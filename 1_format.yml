target_default: 1_format

packages:
  - zeallot
  - readr
  - yaml
  - googledrive
  - scipiper
  - dplyr

sources:
  - lib/src/utils.R
  - 1_format/src/format_tasks.R
  - 1_format/src/calculate_priority_lakes.R

targets:
  1_format:
    depends:
      - 1_format/log/1_format_tasks.ind

  # read and subset the NN settings
  settings:
    command: yaml.load_file('lib/cfg/settings.yml')
  combine_cfg:
    command: settings[I(c('min_obs_per_depth', 'min_obs_per_date'))]
  format_cfg:
    command: settings[I(c('structure'))]
  split_scale_cfg:
    command: settings[I(c('dev_frac', 'test_frac'))]

  # get temperature observations from pipeline #1
  in/merged_temp_data_daily.feather:
    command: gd_get(ind_file = 'in/merged_temp_data_daily.feather.ind')

  # get lake metadata (for names) from pipeline #1
  in/feature_crosswalk.rds:
    command: gd_get(ind_file = 'in/feature_crosswalk.rds.ind')

  priority_lakes_by_choice:
   command: get_site_ids(file = 'lib/crosswalks/pipeline_3_lakes.csv')

  priority_lakes_by_data:
    command: calc_priority_lakes(temp_dat = 'in/merged_temp_data_daily.feather', n_min = 2000, n_years = 30, years_with_7months = 10, years_with_10days = 20, n_days = 1000)

  priority_lakes:
    command: combine_priorities(priority_lakes_by_choice, priority_lakes_by_data, name_crosswalk = 'in/feature_crosswalk.rds')

  site_ids:
    command: get_site_ids(file = 'lib/crosswalks/pipeline_3_lakes.csv', test = I(TRUE))

  #once GLM outputs are ready, switch this over to priorty_lakes

  format_data_task_plan:
    command: create_format_task_plan(site_ids, ind_dir = I("1_format"))

  1_format_tasks.yml:
    command: create_format_task_makefile(task_plan = format_data_task_plan, makefile = target_name, ind_complete=TRUE)

  1_format/log/1_format_tasks.ind:
    command: loop_tasks(task_plan = format_data_task_plan, task_makefile = '1_format_tasks.yml', num_tries=1)
